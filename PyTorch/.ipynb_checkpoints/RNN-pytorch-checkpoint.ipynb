{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as Data \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "#Hyper Parameters\n",
    "EPOCH = 2\n",
    "BATCH_SIZE = 64\n",
    "INPUT_SIZE = 28\n",
    "TIME_STEP = 28\n",
    "LR = 0.01\n",
    "DOWNLOAD_MNISIT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='./mnist',\n",
    "    train=True,\n",
    "    transform = transforms.ToTensor(),\n",
    "    download=DOWNLOAD_MNISIT\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = Data.DataLoader(dataset=train_data,batch_size=BATCH_SIZE,\n",
    "                              shuffle=True)\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    root='./mnist',\n",
    "    train=False,\n",
    "    transform = transforms.ToTensor()\n",
    ")\n",
    "test_x = torch.unsqueeze(test_data.test_data,dim=1).type(torch.FloatTensor)[:2000]/255\n",
    "test_y = test_data.test_labels[:2000]\n",
    "test_x = test_x.cuda()\n",
    "test_y = test_y.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn): LSTM(28, 64, batch_first=True)\n",
      "  (out): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN,self).__init__()\n",
    "        self.rnn=nn.LSTM(\n",
    "            input_size =INPUT_SIZE,\n",
    "            hidden_size =64,\n",
    "            num_layers =1,\n",
    "            batch_first = True,\n",
    "        )\n",
    "        self.out = nn.Linear(64,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        r_out,(h_n,h_c)=self.rnn(x,None)\n",
    "        out = self.out(r_out[:,-1,:]) #(batch,time step,input)\n",
    "        return out\n",
    "\n",
    "rnn = RNN()\n",
    "rnn.cuda()\n",
    "print(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "print(test_y.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 | step:  0 | train loss:2.2883 | test accuracy:0.102\n",
      "epoch:  0 | step:  50 | train loss:1.0933 | test accuracy:0.619\n",
      "epoch:  0 | step:  100 | train loss:0.9901 | test accuracy:0.766\n",
      "epoch:  0 | step:  150 | train loss:0.5377 | test accuracy:0.786\n",
      "epoch:  0 | step:  200 | train loss:0.2820 | test accuracy:0.854\n",
      "epoch:  0 | step:  250 | train loss:0.2429 | test accuracy:0.901\n",
      "epoch:  0 | step:  300 | train loss:0.4214 | test accuracy:0.905\n",
      "epoch:  0 | step:  350 | train loss:0.4387 | test accuracy:0.891\n",
      "epoch:  0 | step:  400 | train loss:0.1261 | test accuracy:0.931\n",
      "epoch:  0 | step:  450 | train loss:0.1285 | test accuracy:0.933\n",
      "epoch:  0 | step:  500 | train loss:0.0561 | test accuracy:0.937\n",
      "epoch:  0 | step:  550 | train loss:0.2149 | test accuracy:0.940\n",
      "epoch:  0 | step:  600 | train loss:0.1386 | test accuracy:0.944\n",
      "epoch:  0 | step:  650 | train loss:0.2413 | test accuracy:0.928\n",
      "epoch:  0 | step:  700 | train loss:0.1298 | test accuracy:0.944\n",
      "epoch:  0 | step:  750 | train loss:0.1020 | test accuracy:0.952\n",
      "epoch:  0 | step:  800 | train loss:0.0709 | test accuracy:0.936\n",
      "epoch:  0 | step:  850 | train loss:0.0763 | test accuracy:0.955\n",
      "epoch:  0 | step:  900 | train loss:0.2546 | test accuracy:0.962\n",
      "epoch:  1 | step:  0 | train loss:0.1251 | test accuracy:0.956\n",
      "epoch:  1 | step:  50 | train loss:0.0513 | test accuracy:0.950\n",
      "epoch:  1 | step:  100 | train loss:0.0547 | test accuracy:0.960\n",
      "epoch:  1 | step:  150 | train loss:0.0856 | test accuracy:0.958\n",
      "epoch:  1 | step:  200 | train loss:0.2456 | test accuracy:0.957\n",
      "epoch:  1 | step:  250 | train loss:0.0954 | test accuracy:0.962\n",
      "epoch:  1 | step:  300 | train loss:0.1503 | test accuracy:0.959\n",
      "epoch:  1 | step:  350 | train loss:0.4468 | test accuracy:0.961\n",
      "epoch:  1 | step:  400 | train loss:0.0140 | test accuracy:0.964\n",
      "epoch:  1 | step:  450 | train loss:0.0648 | test accuracy:0.955\n",
      "epoch:  1 | step:  500 | train loss:0.0141 | test accuracy:0.966\n",
      "epoch:  1 | step:  550 | train loss:0.0330 | test accuracy:0.966\n",
      "epoch:  1 | step:  600 | train loss:0.0951 | test accuracy:0.960\n",
      "epoch:  1 | step:  650 | train loss:0.1211 | test accuracy:0.970\n",
      "epoch:  1 | step:  700 | train loss:0.4072 | test accuracy:0.962\n",
      "epoch:  1 | step:  750 | train loss:0.1264 | test accuracy:0.957\n",
      "epoch:  1 | step:  800 | train loss:0.0254 | test accuracy:0.967\n",
      "epoch:  1 | step:  850 | train loss:0.1106 | test accuracy:0.969\n",
      "epoch:  1 | step:  900 | train loss:0.1649 | test accuracy:0.966\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(rnn.parameters(),lr=LR)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "for epoch in range(EPOCH):\n",
    "    for step,(x,b_y) in enumerate(train_loader):\n",
    "        b_x = x.view(-1,28,28).cuda()\n",
    "        b_y=b_y.cuda()\n",
    "        output = rnn(b_x)\n",
    "        loss = loss_func(output,b_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if step%50 ==0:\n",
    "            test_output = rnn(test_x.view(-1,28,28))\n",
    "#             pred_y = torch.max(test_output,1)[1].data.numpy().squeeze()\n",
    "            pred_y = torch.max(test_output,1)[1].cuda().data.squeeze()\n",
    "#             accuracy = sum(pred_y==test_y.numpy())/test_y.size(0)\n",
    "            accuracy = sum(pred_y.cpu().numpy()==test_y.cpu().numpy())/test_y.size(0)\n",
    "            print('epoch: ',epoch,'| step: ',step,'| train loss:%.4f'%loss.data.cpu().numpy(),\n",
    "                 '| test accuracy:%.3f'%accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 6 4 1 4 9 6 9] prediction number\n",
      "[7 2 1 0 4 1 4 9 5 9] real number\n"
     ]
    }
   ],
   "source": [
    "test_output = rnn(test_x[:10].view(-1, 28, 28))\n",
    "# pred_y = torch.max(test_output, 1)[1].data.numpy().squeeze()\n",
    "pred_y = torch.max(test_output, 1)[1].cuda().data.squeeze()\n",
    "print(pred_y.cpu().numpy(), 'prediction number')\n",
    "print(test_y[:10].cpu().numpy(), 'real number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
